{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad1b1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,tokenizer,seq_len,seed_text,num_gen_words):\n",
    "    output=[]\n",
    "    \n",
    "    input_text= seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text=tokenizer.texts_to_sequences([input_text])[0]\n",
    "        pad_encoded=pad_sequences([encoded_text],maxlen=seq_len,truncating='pre')\n",
    "        pred_word_ind=np.argmax(model.predict(pad_encoded,verbose=0)[0])\n",
    "        pred_word=tokenizer.index_word[pred_word_ind]\n",
    "        \n",
    "        input_text+=' '+pred_word\n",
    "        output.append(pred_word)\n",
    "        \n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90d7b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import random\n",
    "from pickle import load,dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a55aef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('../my codes/moby4ch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab0c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=load(open('../my codes/moby4ch','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d4d7a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text=f.read()\n",
    "        \n",
    "    return str_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d22a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anshc\\.conda\\envs\\nlp_course\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88, got 80\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp =spacy.load('en_core_web_lg',disable=['parse','tagger','ner'])\n",
    "nlp.max_length=1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da638eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_punc(doc_text):\n",
    "    return[token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b95f9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=read_files('../UPDATED_NLP_COURSE/06-Deep-Learning/moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f5fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=seperate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "300787fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len=25+1\n",
    "text_seq=[]\n",
    " \n",
    "for i in range(train_len,len(tokens)):\n",
    "    seq=tokens[i-train_len:i]\n",
    "    text_seq.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5ce27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a31f8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(163)\n",
    "random_pick=random.randint(0,len(text_seq))\n",
    "random_seed_text=text_seq[random_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f51ce4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['very',\n",
       " 'sooty',\n",
       " 'so',\n",
       " 'that',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'this',\n",
       " 'fire',\n",
       " 'place',\n",
       " 'made',\n",
       " 'a',\n",
       " 'very',\n",
       " 'appropriate',\n",
       " 'little',\n",
       " 'shrine',\n",
       " 'or',\n",
       " 'chapel',\n",
       " 'for',\n",
       " 'his',\n",
       " 'congo',\n",
       " 'idol',\n",
       " 'i',\n",
       " 'now',\n",
       " 'screwed',\n",
       " 'my',\n",
       " 'eyes']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bba8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text=' '.join(random_seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49ed7aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hard towards the half hidden image feeling but ill at ease meantime to see what was next to follow first he takes about a double'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model,tokenizer,seq_len=25,seed_text=seed_text,num_gen_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45aa678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
